{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run_main.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"vSJwPtoc5BSS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YfkxPA9k5i0F","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[]},{"metadata":{"id":"z9H2MeXX5tXV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!ls"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TGyK4KyE5wl_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# http://pytorch.org/\n","from os import path\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","\n","accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n","import torch"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oZY8Toxs541O","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!ls\n","\n","import os\n","os.chdir('drive/app/nuclei_private-master/data/stage1_train_b/nuclei_private')\n","\n","!ls"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7Y0ANQ0E6bWV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!python3 main.py --use_gpu"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kxgkHC6uW1Hd","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!pip install imageio"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2j5Y0zm3dl7h","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["print(1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"E6WwAR7ceALO","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!ls\n","import os\n","os.chdir('drive')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"i_9UQWwOqvAC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!python3 main.py --use_gpu"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dGB4A3JDXMuv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!git clone https://wxwang0104:wangwenxiao12@github.com/liyang2019/nuclei_private.git "],"execution_count":0,"outputs":[]},{"metadata":{"id":"UyEpfRx6rQzF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":68},"outputId":"882551ea-90de-4af0-d865-fe3a4609c4b5","executionInfo":{"status":"ok","timestamp":1521692102478,"user_tz":300,"elapsed":425,"user":{"displayName":"Wenxiao Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"117358464898569738958"}}},"cell_type":"code","source":["!ls"],"execution_count":24,"outputs":[{"output_type":"stream","text":["data\t    main.py\t    __pycache__\t\t      submission   submit.slurm\r\n","dataset.py  model\t    pytorch-mask-rcnn-master  submitor.py  trainer.py\r\n","log.txt     model_saved.pt  README.md\t\t      submit.py    utils.py\r\n"],"name":"stdout"}]},{"metadata":{"id":"eS43F3cEo8p7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":833},"outputId":"5fd6a449-9945-4333-8c71-2c00f6c9db7d","executionInfo":{"status":"ok","timestamp":1521692905786,"user_tz":300,"elapsed":2252,"user":{"displayName":"Wenxiao Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"117358464898569738958"}}},"cell_type":"code","source":["!python3 main.py --help"],"execution_count":47,"outputs":[{"output_type":"stream","text":["usage: main.py [-h] [--debug] [--use_gpu] [--batch_size BATCH_SIZE]\r\n","               [--num_classes NUM_CLASSES] [--output_dir OUTPUT_DIR]\r\n","               [--model MODEL] [--learning_rate LEARNING_RATE]\r\n","               [--optimizer OPTIMIZER] [--random_seed SEED] [--load_model]\r\n","               [--predict] [--unet_batch_norm] [--unet_use_dropout]\r\n","               [--unet_dropout_rate] [--unet_channels UNET_CHANNELS]\r\n","               [--print_every PRINT_EVERY]\r\n","               [--save_model_every SAVE_MODEL_EVERY] [--crop_size CROP_SIZE]\r\n","               [--pretrained] [--num_epochs NUM_EPOCHS] [--is_validation]\r\n","               [--validation_every VALIDATION_EVERY]\r\n","\r\n","Script to run segmentation models\r\n","\r\n","optional arguments:\r\n","  -h, --help            show this help message and exit\r\n","  --debug               Debug the model\r\n","  --use_gpu             Debug the model\r\n","  --batch_size BATCH_SIZE\r\n","                        desired batch size for training\r\n","  --num_classes NUM_CLASSES\r\n","                        number of classes for prediction\r\n","  --output_dir OUTPUT_DIR\r\n","                        path to saving outputs\r\n","  --model MODEL         model to train on\r\n","  --learning_rate LEARNING_RATE\r\n","                        starting learning rate\r\n","  --optimizer OPTIMIZER\r\n","                        adam or sgd optimizer\r\n","  --random_seed SEED    seed for random initialization\r\n","  --load_model          load model from file\r\n","  --predict             only predict\r\n","  --unet_batch_norm     to choose whether use batch normalization for unet\r\n","  --unet_use_dropout    use unet dropout\r\n","  --unet_dropout_rate   to set the dropout rate for unet\r\n","  --unet_channels UNET_CHANNELS\r\n","                        the number of unet first conv channels\r\n","  --print_every PRINT_EVERY\r\n","                        print loss every print_every steps\r\n","  --save_model_every SAVE_MODEL_EVERY\r\n","                        save model every save_model_every steps\r\n","  --crop_size CROP_SIZE\r\n","                        crop image to this size\r\n","  --pretrained          load pretrained model when doing transfer learning\r\n","  --num_epochs NUM_EPOCHS\r\n","                        total number of epochs for training\r\n","  --is_validation       whether or not calculate validation when training\r\n","  --validation_every VALIDATION_EVERY\r\n","                        calculate validation loss every validation_every step\r\n"],"name":"stdout"}]},{"metadata":{"id":"TKW5RjBUtIaP","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":34},"outputId":"a9e62017-25b0-4272-a03e-970247e4203b","executionInfo":{"status":"ok","timestamp":1521692148413,"user_tz":300,"elapsed":569,"user":{"displayName":"Wenxiao Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"117358464898569738958"}}},"cell_type":"code","source":["!python3 main.py"],"execution_count":28,"outputs":[{"output_type":"stream","text":["python3: can't open file 'main.py': [Errno 2] No such file or directory\r\n"],"name":"stdout"}]},{"metadata":{"id":"9fdgYYjG6P2l","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":34},"outputId":"9d07d232-2f1d-4069-d310-d5040fb0e9cd","executionInfo":{"status":"ok","timestamp":1521692744492,"user_tz":300,"elapsed":4726,"user":{"displayName":"Wenxiao Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"117358464898569738958"}}},"cell_type":"code","source":["!git pull"],"execution_count":41,"outputs":[{"output_type":"stream","text":["Already up-to-date.\r\n"],"name":"stdout"}]},{"metadata":{"id":"IlpQYEsJ9Vyx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!python3 main.py --use_gpu --print_every 100 --save_model_every 100 --unet_batch_norm --crop_size 224"],"execution_count":0,"outputs":[]},{"metadata":{"id":"F4rA_jDy9tjO","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":43},{"item_id":88},{"item_id":133},{"item_id":163}],"base_uri":"https://localhost:8080/","height":3128},"outputId":"064b544c-5d25-488c-a705-d70e0fe1d03f"},"cell_type":"code","source":["!python3 main.py --use_gpu --unet_batch_norm"],"execution_count":0,"outputs":[{"output_type":"stream","text":["./\r\n","random_seed:  100\r\n","debug:  False\r\n","batch size:  1\r\n","num_classes:  2\r\n","output_dir:  ./\r\n","model:  unet\r\n","learning_rate:  0.001\r\n","optimizer:  sgd\r\n","load_model:  False\r\n","predict:  False\r\n","unet unet_batch_norm:  True\r\n","unet_use_dropout:  False\r\n","unet_dropout_rate:  None\r\n","unet_channels:  32\r\n","print_every:  10\r\n","save_model_every:  100\r\n","validation_every:  1\r\n","crop_size:  224\r\n","unet dropout rate:  None\n","Running model: unet\n","gpu:  True\n","training on train set\n","step 9 | loss_train 0.639847457408905 | loss_val None | lr 0.001 | time 1.231471061706543 \n","step 19 | loss_train 0.5100122094154358 | loss_val None | lr 0.001 | time 0.7357609272003174 \n","step 29 | loss_train 0.4938163757324219 | loss_val None | lr 0.001 | time 0.7331595420837402 \n","step 39 | loss_train 0.4853900671005249 | loss_val None | lr 0.001 | time 0.696845531463623 \n","step 49 | loss_train 0.402813196182251 | loss_val None | lr 0.001 | time 0.7214374542236328 \n","step 59 | loss_train 0.3865851163864136 | loss_val None | lr 0.001 | time 0.7064805030822754 \n","step 69 | loss_train 0.3668391704559326 | loss_val None | lr 0.001 | time 0.7678661346435547 \n","step 79 | loss_train 0.3242737054824829 | loss_val None | lr 0.001 | time 0.7464520931243896 \n","step 89 | loss_train 0.41698381304740906 | loss_val None | lr 0.001 | time 0.710019588470459 \n","step 99 | loss_train 0.3069460391998291 | loss_val None | lr 0.001 | time 0.7085089683532715 \n","step 109 | loss_train 0.3057583272457123 | loss_val None | lr 0.001 | time 6.556459665298462 \n","step 119 | loss_train 0.28906717896461487 | loss_val None | lr 0.001 | time 0.7215096950531006 \n","step 129 | loss_train 0.3142710030078888 | loss_val None | lr 0.001 | time 0.7624211311340332 \n","step 139 | loss_train 0.3749327063560486 | loss_val None | lr 0.001 | time 0.6959090232849121 \n","step 149 | loss_train 0.24550071358680725 | loss_val None | lr 0.001 | time 0.6991195678710938 \n","step 159 | loss_train 0.22139708697795868 | loss_val None | lr 0.001 | time 0.747840404510498 \n","step 169 | loss_train 0.23288846015930176 | loss_val None | lr 0.001 | time 0.709235429763794 \n","step 179 | loss_train 0.30706095695495605 | loss_val None | lr 0.001 | time 0.6960294246673584 \n","step 189 | loss_train 0.21598663926124573 | loss_val None | lr 0.001 | time 0.6857481002807617 \n","step 199 | loss_train 0.2783481776714325 | loss_val None | lr 0.001 | time 0.7951314449310303 \n","step 209 | loss_train 0.2554233968257904 | loss_val None | lr 0.001 | time 4.349309921264648 \n","step 219 | loss_train 0.28968730568885803 | loss_val None | lr 0.001 | time 0.7769002914428711 \n","step 229 | loss_train 0.17131982743740082 | loss_val None | lr 0.001 | time 0.685859203338623 \n","step 239 | loss_train 0.1912088394165039 | loss_val None | lr 0.001 | time 0.7055156230926514 \n","step 249 | loss_train 0.16391834616661072 | loss_val None | lr 0.001 | time 0.722928524017334 \n","step 259 | loss_train 0.21318596601486206 | loss_val None | lr 0.001 | time 0.7128763198852539 \n","step 269 | loss_train 0.19526581466197968 | loss_val None | lr 0.001 | time 0.8019239902496338 \n","step 279 | loss_train 0.25146806240081787 | loss_val None | lr 0.001 | time 0.7015254497528076 \n","step 289 | loss_train 0.1735272854566574 | loss_val None | lr 0.001 | time 0.725693941116333 \n","step 299 | loss_train 0.43960943818092346 | loss_val None | lr 0.001 | time 0.708946704864502 \n","step 309 | loss_train 0.14663870632648468 | loss_val None | lr 0.001 | time 4.220423936843872 \n","step 319 | loss_train 0.16121461987495422 | loss_val None | lr 0.001 | time 0.7074389457702637 \n","step 329 | loss_train 0.16135592758655548 | loss_val None | lr 0.001 | time 0.7843244075775146 \n","step 339 | loss_train 0.4936022162437439 | loss_val None | lr 0.001 | time 0.7367279529571533 \n","step 349 | loss_train 0.13066601753234863 | loss_val None | lr 0.001 | time 0.7794170379638672 \n","step 359 | loss_train 0.1268356442451477 | loss_val None | lr 0.001 | time 0.7065374851226807 \n","step 369 | loss_train 0.13042378425598145 | loss_val None | lr 0.001 | time 0.7043187618255615 \n","step 379 | loss_train 0.1432039737701416 | loss_val None | lr 0.001 | time 0.9367673397064209 \n","step 389 | loss_train 0.11291754990816116 | loss_val None | lr 0.001 | time 0.7467577457427979 \n","step 399 | loss_train 0.3068558871746063 | loss_val None | lr 0.001 | time 0.6990928649902344 \n"],"name":"stdout"},{"output_type":"stream","text":["step 409 | loss_train 0.2938315272331238 | loss_val None | lr 0.001 | time 4.241658687591553 \n","step 419 | loss_train 0.10308989882469177 | loss_val None | lr 0.001 | time 0.6937205791473389 \n","step 429 | loss_train 0.34444645047187805 | loss_val None | lr 0.001 | time 0.6999609470367432 \n","step 439 | loss_train 0.11295392364263535 | loss_val None | lr 0.001 | time 0.6850979328155518 \n","step 449 | loss_train 0.17703402042388916 | loss_val None | lr 0.001 | time 0.722074031829834 \n","step 459 | loss_train 0.1824655681848526 | loss_val None | lr 0.001 | time 0.7126123905181885 \n","step 469 | loss_train 0.1242714673280716 | loss_val None | lr 0.001 | time 0.7174351215362549 \n","step 479 | loss_train 0.0905756950378418 | loss_val None | lr 0.001 | time 0.7126078605651855 \n","step 489 | loss_train 0.16011284291744232 | loss_val None | lr 0.001 | time 1.2483789920806885 \n","step 499 | loss_train 0.1001746878027916 | loss_val None | lr 0.001 | time 0.7099864482879639 \n","step 509 | loss_train 0.25781190395355225 | loss_val None | lr 0.001 | time 6.61838960647583 \n","step 519 | loss_train 0.0847754180431366 | loss_val None | lr 0.001 | time 0.7014796733856201 \n","step 529 | loss_train 0.07941112667322159 | loss_val None | lr 0.001 | time 0.7004928588867188 \n","step 539 | loss_train 0.5220643281936646 | loss_val None | lr 0.001 | time 0.21201658248901367 \n","step 549 | loss_train 0.08653796464204788 | loss_val None | lr 0.001 | time 0.6997189521789551 \n","step 559 | loss_train 0.1493528187274933 | loss_val None | lr 0.001 | time 0.7004132270812988 \n","step 569 | loss_train 0.06807831674814224 | loss_val None | lr 0.001 | time 0.7099990844726562 \n","step 579 | loss_train 0.08015331625938416 | loss_val None | lr 0.001 | time 0.7116203308105469 \n","step 589 | loss_train 0.07764200866222382 | loss_val None | lr 0.001 | time 0.7106645107269287 \n","step 599 | loss_train 0.23341809213161469 | loss_val None | lr 0.001 | time 0.7053966522216797 \n","step 609 | loss_train 0.10830319672822952 | loss_val None | lr 0.001 | time 4.3912739753723145 \n","step 619 | loss_train 0.11069714277982712 | loss_val None | lr 0.001 | time 0.6972458362579346 \n","step 629 | loss_train 0.09535033255815506 | loss_val None | lr 0.001 | time 0.685006856918335 \n","step 639 | loss_train 0.1637842059135437 | loss_val None | lr 0.001 | time 0.7101728916168213 \n","step 649 | loss_train 0.15488304197788239 | loss_val None | lr 0.001 | time 0.7175559997558594 \n","step 659 | loss_train 0.17258669435977936 | loss_val None | lr 0.001 | time 0.6874234676361084 \n","step 669 | loss_train 0.0822802260518074 | loss_val None | lr 0.001 | time 0.6945934295654297 \n","step 679 | loss_train 0.0681380033493042 | loss_val None | lr 0.001 | time 0.6922760009765625 \n","step 689 | loss_train 0.07906848937273026 | loss_val None | lr 0.001 | time 0.717038631439209 \n","step 699 | loss_train 0.08218182623386383 | loss_val None | lr 0.001 | time 0.7000119686126709 \n","step 709 | loss_train 0.0853927731513977 | loss_val None | lr 0.001 | time 4.5330970287323 \n","step 719 | loss_train 0.06437233835458755 | loss_val None | lr 0.001 | time 0.6862378120422363 \n","step 729 | loss_train 0.15930868685245514 | loss_val None | lr 0.001 | time 0.7310965061187744 \n","step 739 | loss_train 0.07717575132846832 | loss_val None | lr 0.001 | time 0.7028725147247314 \n","step 749 | loss_train 0.07423687726259232 | loss_val None | lr 0.001 | time 0.7172696590423584 \n","step 759 | loss_train 0.06315675377845764 | loss_val None | lr 0.001 | time 0.6946799755096436 \n","step 769 | loss_train 0.07806311547756195 | loss_val None | lr 0.001 | time 0.7051961421966553 \n","step 779 | loss_train 0.11375121027231216 | loss_val None | lr 0.001 | time 0.6962873935699463 \n","step 789 | loss_train 0.2425122708082199 | loss_val None | lr 0.001 | time 0.7109391689300537 \n","step 799 | loss_train 0.10764869302511215 | loss_val None | lr 0.001 | time 0.6942448616027832 \n","step 809 | loss_train 0.09298309683799744 | loss_val None | lr 0.001 | time 4.202756643295288 \n","step 819 | loss_train 0.07302127778530121 | loss_val None | lr 0.001 | time 0.7041850090026855 \n","step 829 | loss_train 0.07632428407669067 | loss_val None | lr 0.001 | time 0.6930909156799316 \n","step 839 | loss_train 0.063278928399086 | loss_val None | lr 0.001 | time 0.6935286521911621 \n","step 849 | loss_train 0.15591438114643097 | loss_val None | lr 0.001 | time 0.6959326267242432 \n"],"name":"stdout"},{"output_type":"stream","text":["step 859 | loss_train 0.05304150655865669 | loss_val None | lr 0.001 | time 0.7027580738067627 \n","step 869 | loss_train 0.21436083316802979 | loss_val None | lr 0.001 | time 0.6960005760192871 \n","step 879 | loss_train 0.040729496628046036 | loss_val None | lr 0.001 | time 0.7066483497619629 \n","step 889 | loss_train 0.07137564569711685 | loss_val None | lr 0.001 | time 0.7003529071807861 \n","step 899 | loss_train 0.05029226467013359 | loss_val None | lr 0.001 | time 0.6931078433990479 \n","step 909 | loss_train 0.05967709422111511 | loss_val None | lr 0.001 | time 4.749180793762207 \n","step 919 | loss_train 0.2629483938217163 | loss_val None | lr 0.001 | time 0.7215733528137207 \n","step 929 | loss_train 0.14456909894943237 | loss_val None | lr 0.001 | time 0.6913976669311523 \n","step 939 | loss_train 0.3897932767868042 | loss_val None | lr 0.001 | time 0.7063872814178467 \n","step 949 | loss_train 0.16142408549785614 | loss_val None | lr 0.001 | time 0.8784976005554199 \n","step 959 | loss_train 0.15411488711833954 | loss_val None | lr 0.001 | time 0.7081501483917236 \n","step 969 | loss_train 0.05261317640542984 | loss_val None | lr 0.001 | time 0.712482213973999 \n","step 979 | loss_train 0.04622216522693634 | loss_val None | lr 0.001 | time 1.2213776111602783 \n","step 989 | loss_train 0.06186689808964729 | loss_val None | lr 0.001 | time 0.7002928256988525 \n","step 999 | loss_train 0.04766909405589104 | loss_val None | lr 0.001 | time 0.6961169242858887 \n","step 1009 | loss_train 0.06451639533042908 | loss_val None | lr 0.001 | time 6.478046894073486 \n","step 1019 | loss_train 0.14091944694519043 | loss_val None | lr 0.001 | time 0.7259924411773682 \n","step 1029 | loss_train 0.07195836305618286 | loss_val None | lr 0.001 | time 0.6952197551727295 \n","step 1039 | loss_train 0.035769205540418625 | loss_val None | lr 0.001 | time 0.6950156688690186 \n","step 1049 | loss_train 0.05838927999138832 | loss_val None | lr 0.001 | time 0.7078704833984375 \n","step 1059 | loss_train 0.058721620589494705 | loss_val None | lr 0.001 | time 0.7076330184936523 \n","step 1069 | loss_train 0.052440106868743896 | loss_val None | lr 0.001 | time 0.703589677810669 \n","step 1079 | loss_train 0.046080466359853745 | loss_val None | lr 0.001 | time 0.5173771381378174 \n","step 1089 | loss_train 0.12483304738998413 | loss_val None | lr 0.001 | time 0.7561352252960205 \n","step 1099 | loss_train 0.07929825782775879 | loss_val None | lr 0.001 | time 0.7711682319641113 \n","step 1109 | loss_train 0.08407507836818695 | loss_val None | lr 0.001 | time 4.261615991592407 \n","step 1119 | loss_train 0.11150871217250824 | loss_val None | lr 0.001 | time 0.7608284950256348 \n","step 1129 | loss_train 0.03963211923837662 | loss_val None | lr 0.001 | time 0.6894495487213135 \n","step 1139 | loss_train 0.04228561371564865 | loss_val None | lr 0.001 | time 0.6983513832092285 \n","step 1149 | loss_train 0.04076523333787918 | loss_val None | lr 0.001 | time 0.7012057304382324 \n","step 1159 | loss_train 0.05765971913933754 | loss_val None | lr 0.001 | time 0.7024741172790527 \n","step 1169 | loss_train 0.09221392124891281 | loss_val None | lr 0.001 | time 0.6945796012878418 \n","step 1179 | loss_train 0.03529047593474388 | loss_val None | lr 0.001 | time 0.7150206565856934 \n","step 1189 | loss_train 0.12099792808294296 | loss_val None | lr 0.001 | time 0.7049849033355713 \n","step 1199 | loss_train 0.07584435492753983 | loss_val None | lr 0.001 | time 0.7093527317047119 \n","step 1209 | loss_train 0.0639539286494255 | loss_val None | lr 0.001 | time 4.276991367340088 \n","step 1219 | loss_train 0.0654686912894249 | loss_val None | lr 0.001 | time 0.6997442245483398 \n","step 1229 | loss_train 0.16298918426036835 | loss_val None | lr 0.001 | time 0.7191877365112305 \n","step 1239 | loss_train 0.037368424236774445 | loss_val None | lr 0.001 | time 0.7004976272583008 \n","step 1249 | loss_train 0.0397748127579689 | loss_val None | lr 0.001 | time 0.6963229179382324 \n","step 1259 | loss_train 0.07956316322088242 | loss_val None | lr 0.001 | time 0.700397253036499 \n","step 1269 | loss_train 0.07733253389596939 | loss_val None | lr 0.001 | time 0.6905984878540039 \n","step 1279 | loss_train 0.037941426038742065 | loss_val None | lr 0.001 | time 0.6901154518127441 \n","step 1289 | loss_train 0.03589166700839996 | loss_val None | lr 0.001 | time 0.6888415813446045 \n","step 1299 | loss_train 0.056702613830566406 | loss_val None | lr 0.001 | time 0.6939501762390137 \n"],"name":"stdout"},{"output_type":"stream","text":["step 1309 | loss_train 0.0442332923412323 | loss_val None | lr 0.001 | time 4.623741865158081 \n","step 1319 | loss_train 0.06165120005607605 | loss_val None | lr 0.001 | time 0.7210135459899902 \n","step 1329 | loss_train 0.16244198381900787 | loss_val None | lr 0.001 | time 0.7027084827423096 \n","step 1339 | loss_train 0.23601892590522766 | loss_val None | lr 0.001 | time 0.7054646015167236 \n","step 1349 | loss_train 0.04127275571227074 | loss_val None | lr 0.001 | time 0.7067134380340576 \n","step 1359 | loss_train 0.08761290460824966 | loss_val None | lr 0.001 | time 0.7022082805633545 \n","step 1369 | loss_train 0.040515270084142685 | loss_val None | lr 0.001 | time 0.688744306564331 \n","step 1379 | loss_train 0.045182593166828156 | loss_val None | lr 0.001 | time 0.6980171203613281 \n","step 1389 | loss_train 0.09063557535409927 | loss_val None | lr 0.001 | time 0.7136232852935791 \n","step 1399 | loss_train 0.0585392527282238 | loss_val None | lr 0.001 | time 0.713735818862915 \n","step 1409 | loss_train 0.2134414166212082 | loss_val None | lr 0.001 | time 4.1918580532073975 \n","step 1419 | loss_train 0.07892674207687378 | loss_val None | lr 0.001 | time 0.7708098888397217 \n","step 1429 | loss_train 0.2322898656129837 | loss_val None | lr 0.001 | time 0.7157776355743408 \n","step 1439 | loss_train 0.038974516093730927 | loss_val None | lr 0.001 | time 0.6972806453704834 \n","step 1449 | loss_train 0.13833767175674438 | loss_val None | lr 0.001 | time 0.7138016223907471 \n","step 1459 | loss_train 0.03350875899195671 | loss_val None | lr 0.001 | time 0.6849558353424072 \n","step 1469 | loss_train 0.0878760889172554 | loss_val None | lr 0.001 | time 0.721729040145874 \n","step 1479 | loss_train 0.043572619557380676 | loss_val None | lr 0.001 | time 1.3526606559753418 \n","step 1489 | loss_train 0.020428182557225227 | loss_val None | lr 0.001 | time 0.7639477252960205 \n","step 1499 | loss_train 0.07303711026906967 | loss_val None | lr 0.001 | time 0.7081501483917236 \n","step 1509 | loss_train 0.037963222712278366 | loss_val None | lr 0.001 | time 6.750420331954956 \n","step 1519 | loss_train 0.2244148999452591 | loss_val None | lr 0.001 | time 0.7072420120239258 \n","step 1529 | loss_train 0.041268255561590195 | loss_val None | lr 0.001 | time 0.7068710327148438 \n","step 1539 | loss_train 0.03711237385869026 | loss_val None | lr 0.001 | time 0.6987941265106201 \n","step 1549 | loss_train 0.02731950394809246 | loss_val None | lr 0.001 | time 0.7163560390472412 \n","step 1559 | loss_train 0.07850044220685959 | loss_val None | lr 0.001 | time 0.700817346572876 \n","step 1569 | loss_train 0.2622435390949249 | loss_val None | lr 0.001 | time 0.6985113620758057 \n","step 1579 | loss_train 0.045092757791280746 | loss_val None | lr 0.001 | time 0.6869096755981445 \n","step 1589 | loss_train 0.048653971403837204 | loss_val None | lr 0.001 | time 0.6959371566772461 \n","step 1599 | loss_train 0.09478781372308731 | loss_val None | lr 0.001 | time 0.6865475177764893 \n"],"name":"stdout"}]}]}